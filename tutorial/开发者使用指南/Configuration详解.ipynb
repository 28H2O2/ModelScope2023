{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# 配置文件介绍\n",
        "\n",
        "ModelScope框架的核心思想之一是完全的配置化。在ModelHub的模型文件中，必然存在名为configuration.json或configuration.yaml的文件，这个文件\n",
        "存储了模型拉起、推理、训练所需要的（几乎所有的）信息。因此，您可以直接将模型文件传入trainer中训练，或拷贝配置到新的模型中来复制一个SOTA的结果。\n",
        "\n",
        "ModelScope中的配置文件存储了各式各样的配置信息，用以进行数据预处理、模型推理、训练和评估，确保模型推理、训练评估过程的可复现性。 \n",
        "\n",
        "配置文件的格式支持`json`和`yaml`格式，模型仓库中默认的配置文件名称为`configuration.json`，ModelScope支持从模型仓库自动读取配置文件进行推理、训练，也支持使用本地配置文件方式进行相关操作。\n",
        "\n",
        "# 读取和使用模型的配置文件\n",
        "\n",
        "ModelScope有专门的API来读取配置文件。如果您需要读取模型的配置，可以按照如下代码进行：\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true
      },
      "source": [
        "from modelscope.utils.hub import read_config\n",
        "cfg = read_config('damo/nlp_structbert_sentence-similarity_chinese-base')\n",
        "print(cfg)\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "如果您想找到配置文件所在的文件目录，可以使用snapshot_download的能力：\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true
      },
      "source": [
        "from modelscope.utils.hub import snapshot_download\n",
        "model_dir = snapshot_download('damo/nlp_structbert_sentence-similarity_chinese-base')\n",
        "print(model_dir) # ~/.cache/modelscope/hub/*\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "一般来说，ModelScope在您使用训练和推理过程中会隐式地加载配置文件，您无需关心这一过程。\n",
        "例如从远端模型仓库读取配置文件初始化模型预测：\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true
      },
      "source": [
        "from modelscope.pipelines import pipeline\n",
        "word_segmentation = pipeline('word-segmentation')\n",
        "input_str = '今天天气不错，适合出去游玩'\n",
        "print(word_segmentation(input_str))\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "在训练和测试时，您可以从模型仓库下载配置文件到本地，也可以直接本地创建新的配置文件，指定本地配置路径进行使用：\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true
      },
      "source": [
        "from modelscope.trainers import build_trainer\n",
        "from modelscope.msdatasets import MsDataset\n",
        "\n",
        "model_id = 'damo/nlp_structbert_sentence-similarity_chinese-tiny'\n",
        "# Ant Financial Question Matching Corpus (AFQMC) dataset\n",
        "dataset_id = 'clue'\n",
        "\n",
        "train_dataset = MsDataset.load('clue', subset_name='afqmc', split='train')\n",
        "eval_dataset = MsDataset.load('clue', subset_name='afqmc', split='validation')\n",
        "\n",
        "kwargs = dict(\n",
        "    model=model_id,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    max_epochs=2,\n",
        "    #cfg_name='your_configuration.json', #指向自定义的configuration文件\n",
        "    work_dir='tmp')\n",
        "\n",
        "\n",
        "trainer = build_trainer(default_args=kwargs)\n",
        "\n",
        "trainer.train()\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# 配置文件格式\n",
        "配置文件主要包含如下一级字段:\n",
        "\n",
        "- **framework**(必填)： 模型运行所需的框架， 例如pytorch，tensorflow，kaldi等。\n",
        "- **task**(必填)： 模型所支持的任务类型，可以是str或者 str列表。\n",
        "- pipeline(可选):  推理使用的pipeline类型。\n",
        "- model (可选):  模型实例化相关参数配置，具体参数请直接参考对应模型库的configuration.json示例。\n",
        "- dataset(可选):  训练评估过程中使用的数据集配置信息。\n",
        "- preprocessor(可选): 训练评估过程中使用的预处理配置\n",
        "- train(可选)：用以配置训练过程中的超参数，例如模型保存目录、训练轮数、优化器、学习率等参数。\n",
        "- evaluation(可选): 用以配置评估过程中数据读取、评估指标等参数。\n",
        "\n",
        "\n",
        "一个常见的配置文件示例如下\n",
        "```json\n",
        "{\n",
        "    \"framework\": \"pytorch\",\n",
        "    \"task\": \"sentence-similarity\",\n",
        "    \"pipeline\": {\n",
        "        \"type\": \"sentence-similarity\"\n",
        "    },\n",
        "    \"preprocessor\": {\n",
        "        \"type\": \"bert-seq-cls-tokenizer-finetune\",\n",
        "        \"first_sequence\": \"sentence1\",\n",
        "        \"second_sequence\": \"sentence2\"\n",
        "    },\n",
        "    \"model\": {\n",
        "        \"type\": \"structbert\",\n",
        "        \"attention_probs_dropout_prob\": 0.1,\n",
        "        \"position_embedding_type\": \"absolute\",\n",
        "        \"transformers_version\": \"4.6.0.dev0\",\n",
        "        \"type_vocab_size\": 2,\n",
        "        \"use_cache\": true,\n",
        "        \"vocab_size\": 21128\n",
        "    },\n",
        "    \"dataset\": {\n",
        "        \"train\": {\n",
        "            \"name\": \"modelscope/afqmc_small\",\n",
        "            \"split\": \"train\"\n",
        "        },\n",
        "        \"val\": {\n",
        "            \"name\": \"modelscope/afqmc_small\",\n",
        "            \"split\": \"val\"\n",
        "        }\n",
        "    },\n",
        "    \"train\": {\n",
        "        \"work_dir\": \"/tmp\",\n",
        "        \"max_epochs\": 10,\n",
        "        \"dataloader\": {\n",
        "            \"batch_size_per_gpu\": 2,\n",
        "            \"workers_per_gpu\": 1\n",
        "        },\n",
        "        \"optimizer\": {\n",
        "            \"type\": \"SGD\",\n",
        "            \"lr\": 0.01\n",
        "        },\n",
        "        \"lr_scheduler\": {\n",
        "            \"type\": \"StepLR\",\n",
        "            \"step_size\": 2\n",
        "        },\n",
        "        \"hooks\": [{\n",
        "            \"type\": \"CheckpointHook\",\n",
        "            \"interval\": 1\n",
        "        }]\n",
        "    },\n",
        "    \"evaluation\": {\n",
        "        \"dataloader\": {\n",
        "            \"batch_size_per_gpu\": 2,\n",
        "            \"workers_per_gpu\": 1,\n",
        "            \"shuffle\": false\n",
        "        },\n",
        "        \"metrics\": [\"accuracy\"]\n",
        "    }\n",
        "}\n",
        "```\n",
        "\n",
        "下面详细介绍model，dataset，preprocessor，train和evaluation等字段。\n",
        "## model\n",
        "model字段的二级字段**type**字段固定，表示模型注册名称， 其他参数一般根据算法提供者实现的模型初始化参数而定，例如类型为CustomModel的模型类的初始化函数定义如下：\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true
      },
      "source": [
        "@MODELS.register_module('sentence-similarity', 'custom-model')\n",
        "class CustomModel(TorchModel):\n",
        "    def __init__(self, \n",
        "                 attention_probs_dropout_prob=0.1,\n",
        "                 gradient_checkpointing=False,\n",
        "                 hidden_act='gelu',\n",
        "                 hidden_dropout_prob=0.1,\n",
        "                 hidden_size=768,\n",
        "                 initializer_range=0.02,\n",
        "                 intermediate_size=3072,\n",
        "                 layer_norm_eps=1e-12,\n",
        "                 max_position_embeddings=512,\n",
        "                 num_attention_heads=12,\n",
        "                 num_hidden_layers=12,\n",
        "                 pad_token_id=0,\n",
        "                 position_embedding_type='absolute',\n",
        "                 type_vocab_size=2,\n",
        "                 use_cache=True,\n",
        "                 vocab_size=21128):\n",
        "        pass\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "对应的configuration.json中model内容如下：\n",
        "```json\n",
        "{\n",
        "  \"model\": {\n",
        "    \"type\": \"custom-model\",\n",
        "    \"attention_probs_dropout_prob\": 0.1,\n",
        "    \"gradient_checkpointing\": false,\n",
        "    \"hidden_act\": \"gelu\",\n",
        "    \"hidden_dropout_prob\": 0.1,\n",
        "    \"hidden_size\": 768,\n",
        "    \"initializer_range\": 0.02,\n",
        "    \"intermediate_size\": 3072,\n",
        "    \"layer_norm_eps\": 1e-12,\n",
        "    \"max_position_embeddings\": 512,\n",
        "    \"num_attention_heads\": 12,\n",
        "    \"num_hidden_layers\": 12,\n",
        "    \"pad_token_id\": 0,\n",
        "    \"position_embedding_type\": \"absolute\",\n",
        "    \"type_vocab_size\": 2,\n",
        "    \"use_cache\": true,\n",
        "    \"vocab_size\": 21128\n",
        "  }\n",
        "}\n",
        "```\n",
        "可以看到，model中除type字段外，其他字段和__init__的入参是一一对应的。每种模型的model字段各不相同，具体请参考ModelScope的[模型文档]()。\n",
        "\n",
        "但是，有几种情况不符合上面的信息：\n",
        "- 部分模型是根据静态方法_instantiate()进行初始化的(当模型存在静态方法_instantiate的时候，否则会如同上例一样使用构造初始化)，在这种情况下，model中的字段对应的是_instantiate方法的入参\n",
        "- 部分模型的codebase来自于transformers等其他框架，因此模型初始化参数在config.json中，这时候model的字段只有type是生效的，如果需要修改模型配置请修改config.json文件的内容，或在模型加载时动态传入\n",
        "\n",
        "未来我们会移除config.json文件，使model配置完全融合到configuration.json中。\n",
        "\n",
        "## dataset\n",
        "dataset二级字段主要有train、val、test(可选)，用于指定训练集、验证集和测试集信息。\n",
        "```json\n",
        "{\n",
        "  \"dataset\": {\n",
        "    \"train\": {\n",
        "      \"name\": \"modelscope/afqmc_small\",\n",
        "      \"split\": \"train\"\n",
        "    },\n",
        "    \"val\": {\n",
        "      \"name\": \"modelscope/afqmc_small\",\n",
        "      \"split\": \"val\"\n",
        "    }\n",
        "  }\n",
        "}\n",
        "```\n",
        "dataset各子key内部支持的信息如下：\n",
        "\n",
        "| key值          |                                                   含义 |\n",
        "|---------------|-----------------------------------------------------:|\n",
        "| namespace     |     [对应MsDataset.load的namespace参数](../数据集/数据集的下载.ipynb) |\n",
        "| target        |        [对应MsDataset.load的target参数](../数据集/数据集的下载.ipynb) |\n",
        "| version       |       [对应MsDataset.load的version参数](../数据集/数据集的下载.ipynb) |\n",
        "| hub           |           [对应MsDataset.load的hub参数](../数据集/数据集的下载.ipynb) |\n",
        "| subset_name   |   [对应MsDataset.load的subset_name参数](../数据集/数据集的下载.ipynb) |\n",
        "| split         |         [对应MsDataset.load的split参数](../数据集/数据集的下载.ipynb) |\n",
        "| data_dir      |      [对应MsDataset.load的data_dir参数](../数据集/数据集的下载.ipynb) |\n",
        "| data_files    |    [对应MsDataset.load的data_files参数](../数据集/数据集的下载.ipynb) |\n",
        "| download_mode | [对应MsDataset.load的download_mode参数](../数据集/数据集的下载.ipynb) |\n",
        "| data_files    |    [对应MsDataset.load的data_files参数](../数据集/数据集的下载.ipynb) |\n",
        "\n",
        "一般来说，从ModelScope官网上下载的模型不带有dataset字段，这是因为训练的数据集多种多样，需要用户自行选择。\n",
        "因此我们建议dataset字段在训练之前动态写入内存中的cfg中，或将原始configuration.json更新到其他目录再读取出来。\n",
        "\n",
        "## preprocessor\n",
        "预处理器的具体文档可以参考[这里](../ModelScope%20Library教程/数据的预处理.ipynb)\n",
        "preprocessor的配置字段type以及参数和model类似， 根据对应preprocessor类的初始化函数参数决定。\n",
        "```json\n",
        "{\n",
        "    \"preprocessor\": {\n",
        "        \"type\": \"sen-sim-tokenizer\"\n",
        "    }\n",
        "}\n",
        "```\n",
        "上面的例子是NLP领域中，句子相似度的preprocessor。一般来说，每个模态的预处理器都有特定的参数，请查看对应模态的预处理器具体说明。\n",
        "\n",
        "配置文件中的预处理器可以分为训练和测试两个，这时的配置文件类似这样：\n",
        "```json\n",
        "{\n",
        "    \"preprocessor\": {\n",
        "      \"train\": {\n",
        "        \"type\": \"sen-sim-tokenizer\"\n",
        "      },\n",
        "      \"val\": {\n",
        "        \"type\": \"sen-sim-tokenizer\"\n",
        "      }\n",
        "    }\n",
        "}\n",
        "```\n",
        "在某些模态中训练和测试的预处理器是完全不同的。这样的设计有助于帮助不同的模型灵活预处理数据。对于代码读取部分，我们通过preprocessor_mode参数来控制读取的内容：\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true
      },
      "source": [
        "# train时读取train下面的配置，如果不存在train/val子key则读取preprocessor整体下面的配置，否则报错\n",
        "Preprocessor.from_pretrained(model_name_or_path=model_dir, preprocessor_mode='train')\n",
        "# eval/inference时读取val下面的配置，如果不存在train/val子key则读取preprocessor整体下面的配置，否则报错\n",
        "Preprocessor.from_pretrained(model_name_or_path=model_dir, preprocessor_mode='eval')\n",
        "Preprocessor.from_pretrained(model_name_or_path=model_dir, preprocessor_mode='inference')\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "#### train\n",
        "训练参数一般由对应的trainer决定，官方默认提供的Trainer的配置一般有如下二级字段：\n",
        "**注**： 当前提供的Trainer仅支持PyTorch框架训练，参数说明针对PyTorch框架\n",
        "\n",
        "- work_dir：  训练模型保存目录\n",
        "- max_epochs:  最大迭代轮次\n",
        "- dataloader:   训练时Pytorch内部Dataloader的相关参数\n",
        "- optimizer:  训练时所用的optimizer类型和参数，注意所有的参数和pytorch官方的torch.optim提供的[optimizer类](https://pytorch.org/docs/stable/optim.html)初始化参数一致\n",
        "- lr_scheduler： 训练时所用的lr scheduler，参数与pytorch官方的[torch.optim.lr_scheduler](https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate)的接口一致\n",
        "- hooks:  所有回调函数的配置， 支持配置不同回调函数，详细配置可以参考[回调函数机制介绍](./回调函数机制详解.ipynb)\n",
        "```json\n",
        "{\n",
        "  \"train\": {\n",
        "    \"work_dir\": \"/tmp\",\n",
        "    \"max_epochs\": 10,\n",
        "    \"dataloader\": {\n",
        "      \"batch_size_per_gpu\": 2,\n",
        "      \"workers_per_gpu\": 1\n",
        "    },\n",
        "    \"optimizer\": {\n",
        "      \"type\": \"SGD\",\n",
        "      \"lr\": 0.01,\n",
        "      \"options\": {\n",
        "        \"grad_clip\": {\n",
        "          \"max_norm\": 2.0\n",
        "        }\n",
        "      }\n",
        "    },\n",
        "    \"lr_scheduler\": {\n",
        "      \"type\": \"StepLR\",\n",
        "      \"step_size\": 2,\n",
        "      \"options\": {\n",
        "        \"warmup\": {\n",
        "          \"type\": \"LinearWarmup\",\n",
        "          \"warmup_iters\": 2\n",
        "        }\n",
        "      }\n",
        "    },\n",
        "    \"hooks\": [\n",
        "      {\n",
        "        \"type\": \"CheckpointHook\",\n",
        "        \"interval\": 1\n",
        "      },\n",
        "      {\n",
        "        \"type\": \"TextLoggerHook\",\n",
        "        \"interval\": 1\n",
        "      },\n",
        "      {\n",
        "        \"type\": \"IterTimerHook\"\n",
        "      },\n",
        "      {\n",
        "        \"type\": \"EvaluationHook\",\n",
        "        \"interval\": 1\n",
        "      }\n",
        "    ]\n",
        "  }\n",
        "}\n",
        "```\n",
        "\n",
        "在训练时，optimizer和lr_scheduler的一些参数需要运行时写入。比如需要lambda表达式作为入参，或者需要填入训练total_iters等情况。这种情况请具体参考[训练文档](../ModelScope%20Library教程/模型的训练Train.ipynb)。\n",
        "\n",
        "\n",
        "#### evaluation\n",
        "评估部分常用的字段如下\n",
        "\n",
        "- dataloader:  评估时Pytorch内部Dataloader的相关参数\n",
        "- metrics： 评估所用的metric名称，  当前支持的有\n",
        "   - accuracy\n",
        "   - image-denoise-metric\n",
        "   - image-ins-seg-coco-metric\n",
        "   - seq-cls-metric\n",
        "   - token-cls-metric\n",
        "   - text-gen-metric\n",
        "   - image-color-enhance-metric\n",
        "   - image-portrait-enhancement-metric\n",
        " \n",
        "Metric的具体介绍请参考[这里](../ModelScope%20Library教程/模型的评估.ipynb)。\n",
        "```json\n",
        "{\n",
        "  \"evaluation\": {\n",
        "    \"dataloader\": {\n",
        "      \"batch_size_per_gpu\": 2,\n",
        "      \"workers_per_gpu\": 1,\n",
        "      \"shuffle\": false\n",
        "    },\n",
        "    \"metrics\": [\n",
        "      \"accuracy\"\n",
        "    ]\n",
        "  }\n",
        "}\n",
        "```\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
