{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 模型的推理\n",
        "\n",
        "推理在深度学习中表示模型的预测过程。一般来说，推理会使用pipeline（串行管道过程）来执行所需要的操作。一个完整的pipeline一般包括了数据的前处理、\n",
        "模型的前向推理、数据的后处理三个过程。\n",
        "\n",
        "# Pipline介绍\n",
        "\n",
        "pipeline()方法是ModelScope框架上最基础的用户方法之一，可对多种领域的多种模型进行快速推理。通过pipeline()方法，用户可以只需要一行代码即可完成对特定任务的模型推理。\n",
        "ModelScope中pipeline的预处理过程复用了[预处理器](./数据的预处理.ipynb)。由于预处理器支持传入mode参数及configuration中的train/val两种独立的预处理过程，因此您可以在预处理过程中\n",
        "方便地区分处理训练、评估、推理三种情况(评估和推理会复用val过程)。pipeline的模型前向推理过程调用了传入模型的forward方法和模型的postprocess方法，以便返回值不标准的模型可以通过定制化的postprocess\n",
        "方法回传pipeline适配的返回值。pipeline的postprocess会在模型的postprocess方法之后被调用，它返回了最终展现给用户的值。\n",
        "\n",
        "# Pipeline的使用\n",
        "本文简单介绍如何使用`pipeline`方法加载模型进行推理。`pipeline`方法支持按照任务类型、模型名称从模型仓库拉取模型进行进行推理，包含以下几个方面：\n",
        "\n",
        "- 使用pipeline()函数进行推理\n",
        "- 指定特定预处理、特定模型进行推理\n",
        "- 不同场景推理任务示例\n",
        "## 环境准备\n",
        "详细步骤可以参考 [环境安装指南](../快速入门/环境安装.ipynb)。\n",
        "## Pipeline基本用法\n",
        "下面以中文分词任务为例，说明pipeline函数的基本用法。\n",
        "\n",
        "1.  pipeline函数支持指定特定任务名称，加载任务默认模型，创建对应pipeline对象。\n",
        "执行如下python代码 ：\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true
      },
      "source": [
        "from modelscope.pipelines import pipeline\n",
        "word_segmentation = pipeline('word-segmentation')\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " \n",
        "\n",
        "2.  输入文本 \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true
      },
      "source": [
        "input_str = '今天天气不错，适合出去游玩'\n",
        "print(word_segmentation(input_str))\n",
        "{'output': '今天 天气 不错 ， 适合 出去 游玩'}\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " \n",
        "\n",
        "3.  输入多条样本 \n",
        "\n",
        "pipeline对象也支持传入多个样本列表输入，返回对应输出列表，每个元素对应输入样本的返回结果。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true
      },
      "source": [
        "inputs =  ['今天天气不错，适合出去游玩','这本书很好，建议你看看']\n",
        "print(word_segmentation(inputs))\n",
        "[{'output': '今天 天气 不错 ， 适合 出去 游玩'}, {'output': '这 本 书 很 好 ， 建议 你 看看'}]\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "4. 输入一个数据集\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true
      },
      "source": [
        "from modelscope.msdatasets import MsDataset\n",
        "from modelscope.pipelines import pipeline\n",
        "\n",
        "inputs = ['今天天气不错，适合出去游玩', '这本书很好，建议你看看']\n",
        "dataset = MsDataset.load(inputs, target='sentence')\n",
        "word_segmentation = pipeline('word-segmentation')\n",
        "outputs = word_segmentation(dataset)\n",
        "for o in outputs:\n",
        "    print(o)\n",
        "\n",
        "# 输出\n",
        "{'output': '今天 天气 不错 ， 适合 出去 游玩'}\n",
        "{'output': '这 本 书 很 好 ， 建议 你 看看'}\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## 指定预处理、模型进行推理\n",
        "pipeline函数支持传入实例化的预处理对象、模型对象，从而支持用户在推理过程中定制化预处理、模型。\n",
        "\n",
        "1. 创建模型对象并使用指定模型进行推理\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true
      },
      "source": [
        "from modelscope.models import Model\n",
        "from modelscope.pipelines import pipeline\n",
        "\n",
        "model = Model.from_pretrained('damo/nlp_structbert_word-segmentation_chinese-base')\n",
        "word_segmentation = pipeline('word-segmentation', model=model)\n",
        "input = '今天天气不错，适合出去游玩'\n",
        "print(word_segmentation(input))\n",
        "{'output': '今天 天气 不错 ， 适合 出去 游玩'}\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "2. 指定tokenizer预处理，并用已指定的模型和预处理方法进行推理\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true
      },
      "source": [
        "from modelscope.models import Model\n",
        "from modelscope.pipelines import pipeline\n",
        "from modelscope.preprocessors import TokenClassificationPreprocessor\n",
        "\n",
        "model = Model.from_pretrained('damo/nlp_structbert_word-segmentation_chinese-base')\n",
        "tokenizer = TokenClassificationPreprocessor(model.model_dir)\n",
        "word_segmentation = pipeline('word-segmentation', model=model, preprocessor=tokenizer)\n",
        "input = '今天天气不错，适合出去游玩'\n",
        "print(word_segmentation(input))\n",
        "{'output': '今天 天气 不错 ， 适合 出去 游玩'}\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## 不同场景任务推理pipeline使用示例\n",
        "### 图像\n",
        "以人像抠图（'portrait-matting'）为例\n",
        "输入图片：\n",
        "\n",
        "![image_matting.png](./resources/1656989748829-9ab3aa9b-461d-44f8-98fb-c85bc6f670f9.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true
      },
      "source": [
        "import cv2\n",
        "from modelscope.pipelines import pipeline\n",
        "\n",
        "portrait_matting = pipeline('portrait-matting')\n",
        "result = portrait_matting('https://modelscope.oss-cn-beijing.aliyuncs.com/test/images/image_matting.png')\n",
        "cv2.imwrite('result.png', result['output_img'])\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "输出：\n",
        "![result.png](./resources/1656989768092-5470f8ac-cda8-4703-ac98-dbb6fd675b34.png)\n",
        "### \n",
        "### 语音\n",
        "以（'text-to-speech'）为例（注意，当前ModelScope版本tts能力体验依赖python3.7，linux环境，后续会进行扩展）\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true
      },
      "source": [
        "from scipy.io.wavfile import write\n",
        "from modelscope.pipelines import pipeline\n",
        "from modelscope.utils.constant import Tasks\n",
        "from modelscope.outputs import OutputKeys\n",
        "\n",
        "\n",
        "text = '今天北京天气怎么样？'\n",
        "voice = 'zhitian_emo'\n",
        "\n",
        "sambert_hifigan_tts =pipeline(\n",
        "    task=Tasks.text_to_speech, model='damo/speech_sambert-hifigan_tts_zhizhe_emo_zh-cn_16k')\n",
        "output = sambert_hifigan_tts(input=text, voice=voice)\n",
        "pcm = output[OutputKeys.OUTPUT_PCM]\n",
        "write('output.wav', 16000, pcm)\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 多模态\n",
        "以多模态表征模型为例：\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true
      },
      "source": [
        "from modelscope.models import Model\n",
        "from modelscope.pipelines import pipeline\n",
        "from modelscope.utils.constant import Tasks\n",
        "from PIL import Image\n",
        "import requests\n",
        "\n",
        "model = Model.from_pretrained('damo/multi-modal_gemm-vit-large-patch14_generative-multi-modal-embedding')\n",
        "p = pipeline(task=Tasks.generative_multi_modal_embedding, model=model)\n",
        "\n",
        "url = 'http://clip-multimodal.oss-cn-beijing.aliyuncs.com/lingchen/demo/dogs.jpg'\n",
        "image = Image.open(requests.get(url, stream=True).raw)\n",
        "text = 'dogs playing in the grass'\n",
        "\n",
        "img_embedding = p.forward({'image': image})['img_embedding']\n",
        "print('image embedding: {}'.format(img_embedding))\n",
        "\n",
        "text_embedding = p.forward({'text': text})['text_embedding']\n",
        "print('text embedding: {}'.format(text_embedding))\n",
        "\n",
        "image_caption = p.forward({'image': image, 'captioning': True})['caption']\n",
        "print('image caption: {}'.format(image_caption))\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# 当前支持的Task列表\n",
        "以下给出当前支持的 task 类型列表（字符串），以及相应的别名（便于管理）。在ModelScope提供的API中，可直接使用字符串作为task入参，比如\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true
      },
      "source": [
        "from modelscope.pipelines import pipeline\n",
        "pipe = pipeline('portrait-matting')\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "也可以使用Tasks.别名，比如\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true
      },
      "source": [
        "from modelscope.utils.constant import Tasks\n",
        "pipe = pipeline(Tasks.portrait_matting)\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "更多的任务支持也在**不断扩展**中。大家可以通过ModelScope页面上的任务分类来选择心仪的模型，也可以从具体模型的页面上，来获取每个模型使用时对应的范例代码。\n",
        "### 视觉\n",
        "```jsx\n",
        "    # ocr\n",
        "    ocr_detection = 'ocr-detection'\n",
        "    ocr_recognition = 'ocr-recognition'\n",
        "\n",
        "    # human face body related\n",
        "    animal_recognition = 'animal-recognition'\n",
        "    face_detection = 'face-detection'\n",
        "    face_recognition = 'face-recognition'\n",
        "    human_detection = 'human-detection'\n",
        "    human_object_interaction = 'human-object-interaction'\n",
        "    face_image_generation = 'face-image-generation'\n",
        "    body_2d_keypoints = 'body-2d-keypoints'\n",
        "    general_recognition = 'general-recognition'\n",
        "\n",
        "    image_classification = 'image-classification'\n",
        "    image_multilabel_classification = 'image-multilabel-classification'\n",
        "    image_classification_imagenet = 'image-classification-imagenet'\n",
        "    image_classification_dailylife = 'image-classification-dailylife'\n",
        "\n",
        "    image_object_detection = 'image-object-detection'\n",
        "\n",
        "    image_segmentation = 'image-segmentation'\n",
        "    portrait_matting = 'portrait-matting'\n",
        "    text_driven_segmentation = 'text-driven-segmentation'\n",
        "    shop_segmentation = 'shop-segmentation'\n",
        "\n",
        "    # image editing\n",
        "    skin_retouching = 'skin-retouching'\n",
        "    image_super_resolution = 'image-super-resolution'\n",
        "    image_colorization = 'image-colorization'\n",
        "    image_color_enhancement = 'image-color-enhancement'\n",
        "    image_denoising = 'image-denoising'\n",
        "    image_portrait_enhancement = 'image-portrait-enhancement'\n",
        "\n",
        "    # image generation\n",
        "    image_to_image_translation = 'image-to-image-translation'\n",
        "    image_to_image_generation = 'image-to-image-generation'\n",
        "    image_style_transfer = 'image-style-transfer'\n",
        "    image_portrait_stylization = 'image-portrait-stylization'\n",
        "\n",
        "    image_embedding = 'image-embedding'\n",
        "\n",
        "    product_retrieval_embedding = 'product-retrieval-embedding'\n",
        "\n",
        "    # video recognition\n",
        "    live_category = 'live-category'\n",
        "    action_recognition = 'action-recognition'\n",
        "    action_detection = 'action-detection'\n",
        "    video_category = 'video-category'\n",
        "    video_embedding = 'video-embedding'\n",
        "    virtual_try_on = 'virtual-try-on'\n",
        "    crowd_counting = 'crowd-counting'\n",
        "    movie_scene_segmentation = 'movie-scene-segmentation'\n",
        "\n",
        "    # video editing\n",
        "    video_inpainting = 'video-inpainting'\n",
        "\n",
        "    # reid and tracking\n",
        "    video_single_object_tracking = 'video-single-object-tracking'\n",
        "    video_summarization = 'video-summarization'\n",
        "    image_reid_person = 'image-reid-person'\n",
        "```\n",
        "### 自然语言处理\n",
        "```jsx\n",
        "    # nlp tasks\n",
        "    word_segmentation = 'word-segmentation'\n",
        "    part_of_speech = 'part-of-speech'\n",
        "    named_entity_recognition = 'named-entity-recognition'\n",
        "    nli = 'nli'\n",
        "    sentiment_classification = 'sentiment-classification'\n",
        "    sentiment_analysis = 'sentiment-analysis'\n",
        "    sentence_similarity = 'sentence-similarity'\n",
        "    text_classification = 'text-classification'\n",
        "    sentence_embedding = 'sentence-embedding'\n",
        "    passage_ranking = 'passage-ranking'\n",
        "    relation_extraction = 'relation-extraction'\n",
        "    zero_shot = 'zero-shot'\n",
        "    translation = 'translation'\n",
        "    token_classification = 'token-classification'\n",
        "    conversational = 'conversational'\n",
        "    text_generation = 'text-generation'\n",
        "    task_oriented_conversation = 'task-oriented-conversation'\n",
        "    dialog_intent_prediction = 'dialog-intent-prediction'\n",
        "    dialog_state_tracking = 'dialog-state-tracking'\n",
        "    table_question_answering = 'table-question-answering'\n",
        "    sentence_embedding = 'sentence-embedding'\n",
        "    fill_mask = 'fill-mask'\n",
        "    summarization = 'summarization'\n",
        "    question_answering = 'question-answering'\n",
        "    zero_shot_classification = 'zero-shot-classification'\n",
        "    backbone = 'backbone'\n",
        "    text_error_correction = 'text-error-correction'\n",
        "    faq_question_answering = 'faq-question-answering'\n",
        "    conversational_text_to_sql = 'conversational-text-to-sql'\n",
        "    information_extraction = 'information-extraction'\n",
        "    document_segmentation = 'document-segmentation'\n",
        "```\n",
        "\n",
        "下面我们详细介绍几个常用NLP任务的推理过程。\n",
        "\n",
        "#### 文本分类任务的推理\n",
        "\n",
        "ModelScope的文本分类任务有：\n",
        "\n",
        "| 任务编码                     |          任务名称 |\n",
        "|--------------------------|--------------:|\n",
        "| nli                      |        自然语言推理 |\n",
        "| sentiment-classification |          情感分析 |\n",
        "| sentence-similarity      |         句子相似度 |\n",
        "| zero-shot-classification | zero-shot分类任务 |\n",
        "| text-classification      |        一般分类任务 |\n",
        "\n",
        "一般来说表中其他任务可以被视为text-classification的子级任务。由于模型可能存在特异性，因此ModelScope目前让这些任务并列存在，以达到模型和推理的灵活性。\n",
        "在用户使用的时候可以按照子级别任务使用，如果没有明确的子级别任务，可以直接使用text-classification任务。\n",
        "\n",
        "代码样例：\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true
      },
      "source": [
        "from modelscope.models import Model\n",
        "from modelscope.preprocessors import Preprocessor\n",
        "model = Model.from_pretrained('damo/nlp_structbert_sentence-similarity_chinese-base')\n",
        "preprocessor = Preprocessor.from_pretrained('damo/nlp_structbert_sentence-similarity_chinese-base')\n",
        "from modelscope.pipelines import pipeline\n",
        "pipeline_ins = pipeline('text-classification', model=model, preprocessor=preprocessor)\n",
        "print(pipeline_ins(('这是个测试', '这也是个测试')))\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "在pipeline中，上述的所有任务都使用同一个pipeline：`TextClassificationPipeline`。这个pipeline的构造参数包括：\n",
        "- model 一个模型id或包含模型的本地路径或一个模型实例。模型实例可以是Model的子类，或一个torch.nn.Module的实例。\n",
        "- preprocessor 传入模型对应的预处理器。如果未传入，pipeline会尝试使用model.model_dir来创建一个预处理器\n",
        "- first_sequence 第一段语言的key\n",
        "- second_sequence 第二段语言的key\n",
        "- sequence_length 支持的最大输入长度\n",
        "- id2label id和label的mapping关系，如果不传入，pipeline会尝试从preprocessor获取id2label。preprocessor的id2label会从\n",
        "model.model_dir的label_mapping.json或configuration.json或config.json自动获取\n",
        "\n",
        "如果__call__方法传入了str（单句）或tuple（双句），first_sequence和second_sequence两个字段不起作用。\n",
        "\n",
        "传入的模型可以是外部PyTorch模型，只要该模型满足：\n",
        "- 模型返回值是dict，或实现了__getitem__方法，并且可以获取`logits`字段，类型是torch.Tensor\n",
        "- 该模型有配套的预处理器传入，或该外部model实例有model_dir字段，其路径中存在configuration.json用以初始化一个预处理器\n",
        "\n",
        "`TextClassificationPipeline`的返回值是：\n",
        "\n",
        "- scores 各标签的概率值序列\n",
        "- labels 各标签值的序列\n",
        "\n",
        "上述两个序列以升序排列。\n",
        "\n",
        "`TextClassificationPipeline`也是OFA模型的推理pipeline，但目前其返回值和上述返回值不同。\n",
        "\n",
        "#### fill-mask任务\n",
        "\n",
        "ModelScope的fill-mask任务的Pipeline是`FillMaskPipeline`。这个pipeline的构造参数包括：\n",
        "- model 一个模型id或包含模型的本地路径或一个模型实例。模型实例可以是Model的子类，或一个torch.nn.Module的实例。\n",
        "- preprocessor 传入模型对应的预处理器。如果未传入，pipeline会尝试使用model.model_dir来创建一个预处理器\n",
        "- first_sequence 第一段语言的key\n",
        "- sequence_length 支持的最大输入长度\n",
        "\n",
        "如果__call__方法传入了str（单句）或tuple（双句），first_sequence字段不起作用。\n",
        "\n",
        "传入的模型可以是外部PyTorch模型，只要该模型满足：\n",
        "- 模型返回值是dict，或实现了__getitem__方法，并且可以获取`logits`字段和`input_ids`字段，其中input_ids字段代表预处理之后输入模型的token序列，类型是torch.Tensor\n",
        "- 该模型有配套的预处理器传入，或该外部model实例有model_dir字段，其路径中存在configuration.json用以初始化一个预处理器\n",
        "\n",
        "`FillMaskPipeline`的返回值是：\n",
        "\n",
        "- text 生成的句子\n",
        "\n",
        "代码样例：\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true
      },
      "source": [
        "from modelscope.pipelines import pipeline\n",
        "pipeline_ins = pipeline('fill-mask', model='damo/nlp_structbert_fill-mask_english-large')\n",
        "input = 'Everything in [MASK] you call reality is really [MASK] a reflection of your [MASK].'\n",
        "print(pipeline_ins(input))\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "如果输入是中文，由于各输入模型的tokenizer不同，部分模型最后返回的text可能存在多余的空格。\n",
        "\n",
        "### 语音\n",
        "```jsx\n",
        "    # audio tasks\n",
        "    auto_speech_recognition = 'auto-speech-recognition'\n",
        "    text_to_speech = 'text-to-speech'\n",
        "    speech_signal_process = 'speech-signal-process'\n",
        "    acoustic_echo_cancellation = 'acoustic-echo-cancellation'\n",
        "    acoustic_noise_suppression = 'acoustic-noise-suppression'\n",
        "    keyword_spotting = 'keyword-spotting'\n",
        "```\n",
        "### 多模态\n",
        "```jsx\n",
        "    # multi-modal tasks\n",
        "    image_captioning = 'image-captioning'\n",
        "    visual_grounding = 'visual-grounding'\n",
        "    text_to_image_synthesis = 'text-to-image-synthesis'\n",
        "    multi_modal_embedding = 'multi-modal-embedding'\n",
        "    generative_multi_modal_embedding = 'generative-multi-modal-embedding'\n",
        "    multi_modal_similarity = 'multi-modal-similarity'\n",
        "    visual_question_answering = 'visual-question-answering'\n",
        "    visual_entailment = 'visual-entailment'\n",
        "    video_multi_modal_embedding = 'video-multi-modal-embedding'\n",
        "    image_text_retrieval = 'image-text-retrieval'\n",
        "```\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
