{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "在整个训练过程中，我们可以利用回调函数在训练的不同时刻定义一些自定义操作：每到达某个时刻，会调用所有回调在该时刻的回调函数，其工作机制可参考下图：\n",
        "![image.png](./resources/1659498714468-3b672c47-c504-403b-987a-983612a2ca9f.png)\n",
        "### 支持列表\n",
        "\n",
        "- LrSchedulerHook\n",
        "- PlateauLrSchedulerHook\n",
        "- OptimizerHook\n",
        "- TorchAMPOptimizerHook\n",
        "- CheckpointHook\n",
        "- BestCkptSaverHook\n",
        "- EvaluationHook\n",
        "- TextLoggerHook\n",
        "- IterTimerHook\n",
        "### 使用方法\n",
        "#### LrSchedulerHook\n",
        "参考API：`modelscope.trainers.hooks.LrSchedulerHook`。\n",
        "用于调节learning rate，`LrSchedulerHook`**不需要用户手动配置**，会在trainer接口中自动为用户创建，我们已将torch支持的所有lr scheduler接口注册到modelscope中，用户只需要在配置文件中配置lr scheduler的类型和参数即可。参考如下配置（需要自定义接口的用户请参考自定义lr_scheduler_hook。）：\n",
        "`StepLR`对应 [torch.optim.lr_scheduler.StepLR](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.StepLR.html) 接口，step_size是`torch.optim.lr_scheduler.StepLR`的参数。\n",
        "```json\n",
        "\"train\": {\n",
        "        \"lr_scheduler\": {\n",
        "            \"type\": \"StepLR\",\n",
        "            \"step_size\": 2,\n",
        "        }\n",
        "}\n",
        "```\n",
        "另外，我们还支持了warmup等附加功能，配置在options参数中，参考如下配置：\n",
        "```json\n",
        "\"train\": {\n",
        "        \"lr_scheduler\": {\n",
        "            \"type\": \"StepLR\",\n",
        "            \"step_size\": 2,\n",
        "            \"options\": {\n",
        "                \"warmup\": {\n",
        "                    \"type\": \"LinearWarmup\",\n",
        "                    \"warmup_iters\": 2\n",
        "\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "}\n",
        "```\n",
        "\n",
        "-  warmup\n",
        "目前我们支持的warmup接口有： \n",
        "   -  `LinearWarmup`\n",
        "参数如下： \n",
        "      - `warmup_iters`: warmup的迭代数。\n",
        "      - `warmup_ratio`：warmup的初始值比例， initial warmup lr=warmup_ratio * initial lr\n",
        "   -  `ConstantWarmup`\n",
        "参数同`LinearWarmup`。 \n",
        "   -  `ExponentialWarmup`\n",
        "参数同`LinearWarmup`。 \n",
        "#### PlateauLrSchedulerHook\n",
        "**注意：`**`**ReduceLROnPlateau**`**`与其他 lr scheduler稍有不同，请参考**[**ReduceLROnPlateau**](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.ReduceLROnPlateau.html)**，**`**ReduceLROnPlateau.step**`**更新时需要用户传入**`**metrics**`**，所以使用时必须增加**`**lr_scheduler_hook**`**字段，指定**`**PlateauLrSchedulerHook**`**。**\n",
        "**关于**`**lr_scheduler_hook**`**字段请参考 **自定义lr_scheduler_hook。\n",
        "参考API：`modelscope.trainers.hooks.PlateauLrSchedulerHook`。\n",
        "仅用于`ReduceLROnPlateau` ，**需要用户手动添加到配置文件中**。`ReduceLROnPlateau.step`需要用户传入`metrics`，必须配合EvaluationHook一起使用，根据验证的返回指标判断learning rate是否需要更新， `ReduceLROnPlateau`的更新频率默认和`EvaluationHook`一致，建议`EvaluationHook`的intervel设置成1。配置参考如下：\n",
        "```json\n",
        "\"train\": {\n",
        "        \"lr_scheduler\": {\n",
        "        \t\t\"type\": \"ReduceLROnPlateau\",\n",
        "            \"mode\": \"max\",\n",
        "            \"factor\": 0.1,\n",
        "            \"patience\": 10,\n",
        "         },\n",
        "        \"lr_scheduler_hook\": {\n",
        "            \"type\": \"PlateauLrSchedulerHook\",\n",
        "            \"metric_key\": \"accuracy\"\n",
        "        }\n",
        "}\n",
        "```\n",
        "\n",
        "- metric_key：metric可能返回多个指标，指定某一个key用于监控趋势，判断是否更新learning rate。\n",
        "#### OptimizerHook\n",
        "参考API：`modelscope.trainers.hooks.OptimizerHook`。\n",
        "用于optimizer更新，`OptimizerHook`**不需要用户手动配置**，会在trainer接口中自动为用户创建，我们已将torch支持的所有optimizer接口注册到ModelScope中，用户只需要在配置文件中配置optimizer的类型和参数即可。参考如下配置（需要自定义接口的用户请参考自定义optimizer_hook。）：\n",
        "```json\n",
        "\"train\": {\n",
        "        \"optimizer\": {\n",
        "            \"type\": \"SGD\",\n",
        "            \"lr\": 0.01\n",
        "        }\n",
        "}\n",
        "```\n",
        "另外，我们还支持了梯度裁剪，梯度累积等操作，附加功能配置在options参数中，参考如下配置：\n",
        "```json\n",
        "\"train\": {\n",
        "        \"optimizer\": {\n",
        "            \"type\": \"SGD\",\n",
        "            \"lr\": 0.01,\n",
        "            \"options\": {\n",
        "                \"grad_clip\": {\n",
        "                    \"max_norm\": 2.0\n",
        "                },\n",
        "              \t\"cumulative_iters\": 2\n",
        "            }\n",
        "        }\n",
        "}\n",
        "```\n",
        "\n",
        "-  grad_clip：梯度裁剪配置 \n",
        "-  cumulative_iters：梯度累积步数 \n",
        "#### TorchAMPOptimizerHook\n",
        "参考API：`modelscope.trainers.hooks.TorchAMPOptimizerHook`。\n",
        "混合精度训练，**不需要用户手动配置**，创建trainer时传入`use_fp16`参数即可。\n",
        "#### CheckpointHook\n",
        "参考API：`modelscope.trainers.hooks.CheckpointHook`。\n",
        "用于保存模型，需要用户手动添加到配置文件中。参考如下配置：\n",
        "```json\n",
        "\"train\": {\n",
        "        \"hooks\":\n",
        "          [\n",
        "            {\n",
        "              \"type\": \"CheckpointHook\",\n",
        "              \"interval\": 1\n",
        "            }\n",
        "          ]\n",
        "}\n",
        "```\n",
        "\n",
        "- interval：保存模型的频率，默认1个epoch保存一次。\n",
        "#### BestCkptSaverHook\n",
        "参考API：`modelscope.trainers.hooks.BestCkptSaverHook`。\n",
        "用于保存指标最优的模型，需要用户手动添加到配置文件中。需配合EvaluationHook使用，根据验证的返回指标判断当前指标是否最优，参考如下配置：\n",
        "```json\n",
        "\"train\": {\n",
        "        \"hooks\":\n",
        "            [\n",
        "              {\n",
        "                \"type\": \"BestCkptSaverHook\",\n",
        "                \"metric_key\": \"accuracy\",\n",
        "                \"rule\": \"max\"\n",
        "              }\n",
        "            ]\n",
        "}\n",
        "```\n",
        "\n",
        "- metric_key：metric可能返回多个指标，指定某一个key用于监控是否是最优模型。\n",
        "- rule：判断规则，\"max\"表示当前\"metric_key\"最大时是最优模型，\"min\"表示当前\"metric_key\"最小时是最优模型。\n",
        "#### EvaluationHook\n",
        "参考API：`modelscope.trainers.hooks.EvaluationHook`。\n",
        "用于边训练边验证，需要用户手动添加到配置文件中。参考如下配置：\n",
        "```json\n",
        "\"train\": {\n",
        "        \"hooks\":\n",
        "            [\n",
        "              {\n",
        "                \"type\": \"EvaluationHook\",\n",
        "                \"interval\": 1\n",
        "              }\n",
        "            ]\n",
        "}\n",
        "```\n",
        "\n",
        "- interval：验证的频率，默认1个epoch验证一次。\n",
        "#### TextLoggerHook\n",
        "参考API：`modelscope.trainers.hooks.TextLoggerHook`。\n",
        "用于打印日志，需要用户手动添加到配置文件中。参考如下配置：\n",
        "```json\n",
        "\"train\": {\n",
        "        \"hooks\":\n",
        "            [\n",
        "              {\n",
        "                \"type\": \"TextLoggerHook\",\n",
        "                \"interval\": 10\n",
        "              }\n",
        "            ]\n",
        "}\n",
        "```\n",
        "\n",
        "- interval：打印日志的频率，默认10步打印一次。\n",
        "#### IterTimerHook\n",
        "参考API：`modelscope.trainers.hooks.IterTimerHook`。\n",
        "用于输出每一步的运行时间以及数据加载时间，需要用户手动添加到配置文件中。参考如下配置：\n",
        "```json\n",
        "\"train\": {\n",
        "        \"hooks\":\n",
        "            [\n",
        "              {\n",
        "                \"type\": \"IterTimerHook\",\n",
        "              }\n",
        "            ]\n",
        "}\n",
        "```\n",
        "### Trainer默认Hook配置\n",
        "需要手动配置的常用Hook，我们已经添加到默认配置中，不需要用户再配置，可参考：`modelscope.trainers.default_config.DEFAULT_CONFIG`。\n",
        "如果用户需要修改默认配置，直接在自己的配置文件中重新添加即可，默认配置会被替换。\n",
        "```json\n",
        "{\n",
        "    \"train\": {\n",
        "        \"hooks\": [\n",
        "          {\n",
        "            \"type\": \"CheckpointHook\",\n",
        "            \"interval\": 1\n",
        "        \t}, \n",
        "          {\n",
        "            \"type\": \"TextLoggerHook\",\n",
        "            \"interval\": 10\n",
        "        \t}, \n",
        "          {\n",
        "            \"type\": \"IterTimerHook\"\n",
        "        \t}\n",
        "        ]\n",
        "    }\n",
        "}\n",
        "```\n",
        "### 自定义Hook\n",
        "#### 自定义通用hook\n",
        "自定义Hook需继承基类`modelscope.trainers.hooks.Hook`，同时将接口注册到`HOOKS`模块中。请参考如下代码：\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "editable": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from modelscope.trainers.hooks import Hook\n",
        "from modelscope.trainers.hooks import HOOKS\n",
        "\n",
        "\n",
        "@HOOKS.register_module()\n",
        "class CustomHook(Hook):\n",
        "  \t\tpass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "自定义后的接口可以在配置文件中直接使用。例如：\n",
        "```json\n",
        "\"train\": {\n",
        "        \"hooks\":\n",
        "            [\n",
        "              {\n",
        "                \"type\": \"CustomHook\",\n",
        "              }\n",
        "            ]\n",
        "}\n",
        "```\n",
        "#### 自定义optimizer_hook\n",
        "**注意：目前我们将**`**optimizer_hook**`**与其他Hook区分开来，自定义的optimizer hook必须使用**`**optimizer_hook**`**字段指定。**\n",
        "默认optimizer_hook请参考OptimizerHook。\n",
        "自定义Hook需继承基类`modelscope.trainers.hooks.Hook`，同时将接口注册到`HOOKS`模块中。请参考如下代码：\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "editable": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from modelscope.trainers.hooks import Hook\n",
        "from modelscope.trainers.hooks import HOOKS\n",
        "\n",
        "\n",
        "@HOOKS.register_module()\n",
        "class CustomOptimizerHook(Hook):\n",
        "  \t\tpass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "自定义optimizer_hook的使用方式如下：\n",
        "```json\n",
        "\"train\": {\n",
        "        \"optimizer\": {\n",
        "            \"type\": \"SGD\",\n",
        "            \"lr\": 0.01\n",
        "        },\n",
        "         \"optimizer_hook\": {\n",
        "             \"type\": \"CustomOptimizerHook\",\n",
        "         }\n",
        "}\n",
        "```\n",
        "#### 自定义lr_scheduler_hook\n",
        "**注意：目前我们将**`lr_scheduler_hook`**与其他Hook区分开来，自定义的lr scheduler hook必须使用**`lr_scheduler_hook`**字段指定。**\n",
        "默认lr_scheduler_hook请参考LrSchedulerHook。\n",
        "自定义Hook需继承基类`modelscope.trainers.hooks.Hook`，同时将接口注册到`HOOKS`模块中。请参考如下代码：\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "editable": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from modelscope.trainers.hooks import Hook\n",
        "from modelscope.trainers.hooks import HOOKS\n",
        "\n",
        "\n",
        "@HOOKS.register_module()\n",
        "class CustomLrSchedulerHook(Hook):\n",
        "  \t\tpass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "自定义lr_scheduler_hook的使用方式如下：\n",
        "```json\n",
        "\"train\": {\n",
        "        \"lr_scheduler\": {\n",
        "            \"type\": \"StepLR\",\n",
        "            \"step_size\": 2,\n",
        "        },\n",
        "         \"lr_scheduler_hook\": {\n",
        "             \"type\": \"CustomLrSchedulerHook\",\n",
        "         },\n",
        "}\n",
        "```\n",
        "### 配置参考\n",
        "```json\n",
        "{\n",
        "    \"framework\": \"pytorch\",\n",
        "    \"task\": \"image_classification\",\n",
        "    \"work_dir\": \"./work_dir\",\n",
        "    \"model\": {},\n",
        "    \"dataset\": {},\n",
        "    \"preprocessor\":{},\n",
        "    \"train\": {\n",
        "        \"dataloader\": {\n",
        "            \"batch_size_per_gpu\": 2,\n",
        "            \"workers_per_gpu\": 1\n",
        "        },\n",
        "        \"optimizer\": {\n",
        "            \"type\": \"SGD\",\n",
        "            \"lr\": 0.01,\n",
        "            \"options\": {\n",
        "                \"grad_clip\": {\n",
        "                    \"max_norm\": 2.0\n",
        "                }\n",
        "            }\n",
        "        },\n",
        "        \"lr_scheduler\": {\n",
        "            \"type\": \"StepLR\",\n",
        "            \"step_size\": 2,\n",
        "            \"options\": {\n",
        "                \"warmup\": {\n",
        "                    \"type\": \"LinearWarmup\",\n",
        "                    \"warmup_iters\": 2\n",
        "\n",
        "                }\n",
        "            }\n",
        "        },\n",
        "        \"hooks\":\n",
        "            [\n",
        "                {\n",
        "                    \"type\": \"CheckpointHook\",\n",
        "                    \"interval\": 2\n",
        "                },\n",
        "                {\n",
        "                    \"type\": \"TextLoggerHook\",\n",
        "                    \"interval\": 20\n",
        "                },\n",
        "                {\n",
        "                    \"type\": \"EvaluationHook\",\n",
        "                    \"interval\": 2\n",
        "                }\n",
        "            ]\n",
        "    },\n",
        "\n",
        "    \"evaluation\": {\n",
        "    \t\t\"dataloader\": {\n",
        "        \t\t\"batch_size_per_gpu\": 2,\n",
        "            \"workers_per_gpu\": 1,\n",
        "            \"shuffle\": false\n",
        "        },\n",
        "        \"metrics\": [\"SequenceClassificationMetric\"]\n",
        "    }\n",
        "}\n",
        "```\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
