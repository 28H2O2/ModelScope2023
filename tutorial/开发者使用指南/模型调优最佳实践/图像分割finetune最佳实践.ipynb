{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "本篇文档展示了如何在自定义数据集上微调预训练的modelscope视觉实例分割模型Cascde Mask RCNN Swin。\n",
        "### 载入数据\n",
        "本模型支持任意具有COCO格式的数据集，包括官方COCO数据集和用户自定义数据集。COCO 格式的实例分割标注的必要字段如下，完整的细节可参考[这里](https://cocodataset.org/#format-data)：\n",
        "```json\n",
        "{\n",
        "    \"images\": [image],\n",
        "    \"annotations\": [annotation],\n",
        "    \"categories\": [category]\n",
        "}\n",
        "\n",
        "\n",
        "image = {\n",
        "    \"id\": int,\n",
        "    \"width\": int,\n",
        "    \"height\": int,\n",
        "    \"file_name\": str,\n",
        "}\n",
        "\n",
        "annotation = {\n",
        "    \"id\": int,\n",
        "    \"image_id\": int,\n",
        "    \"category_id\": int,\n",
        "    \"segmentation\": RLE or [polygon],\n",
        "    \"area\": float,\n",
        "    \"bbox\": [x,y,width,height],\n",
        "    \"iscrowd\": 0 or 1,\n",
        "}\n",
        "\n",
        "categories = [{\n",
        "    \"id\": int,\n",
        "    \"name\": str,\n",
        "    \"supercategory\": str,\n",
        "}]\n",
        "```\n",
        "\n",
        "我们提供了一个toy数据集Pets，该数据集来自[Oxford-IIIT Pet](https://www.robots.ox.ac.uk/~vgg/data/pets/)，已做过格式转换，并存放在modelhub上，用户可通过如下方式调用：\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true
      },
      "source": [
        "mport os\n",
        "from functools import partial\n",
        "\n",
        "from modelscope.hub.snapshot_download import snapshot_download\n",
        "from modelscope.models.cv.image_instance_segmentation import \\\n",
        "    CascadeMaskRCNNSwinModel\n",
        "from modelscope.trainers import build_trainer\n",
        "from modelscope.utils.config import Config, ConfigDict\n",
        "from modelscope.utils.constant import ModelFile\n",
        "\n",
        "from mmcv.parallel import collate\n",
        "\n",
        "model_id = 'damo/cv_swin-b_image-instance-segmentation_coco'\n",
        "cache_path = snapshot_download(model_id)\n",
        "config_path = os.path.join(cache_path, ModelFile.CONFIGURATION)\n",
        "cfg = Config.from_file(config_path)\n",
        "\n",
        "max_epochs = cfg.train.max_epochs\n",
        "samples_per_gpu = cfg.train.dataloader.batch_size_per_gpu\n",
        "train_data_cfg = ConfigDict(\n",
        "                name='pets_small', split='train', test_mode=False)\n",
        "val_data_cfg = ConfigDict(\n",
        "                name='pets_small', split='validation', test_mode=True)\n",
        "\n",
        "train_dataset = MsDataset.load(\n",
        "    dataset_name=train_data_cfg.name,\n",
        "    split=train_data_cfg.split,\n",
        "    test_mode=train_data_cfg.test_mode)\n",
        "\n",
        "eval_dataset = MsDataset.load(\n",
        "    dataset_name=val_data_cfg.name,\n",
        "    split=val_data_cfg.split,\n",
        "    test_mode=val_data_cfg.test_mode)\n",
        "\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "其中，train_dataset和eval_dataset分别定义训练数据集和验证数据集，参数ann_file表示COCO的标注文件JSON的绝对路径，img_prefix表示图片所在文件夹的绝对路径。\n",
        "### 数据预处理\n",
        "训练和测试时的预处理均在Preprocessor中实现。Modelscope提供了一个较为通用的实例分割preprocessor：`image-instance-segmentation-preprocessor`。在配置文件中传入该preprocessor，trainer在build阶段就会自动加载该preprocessor，并根据当前Model状态自动切换为`train`或`eval`所对应的预处理。\n",
        "下面示例展示了具体preprocessor的配置，其中type指定preprocessor类型为`image-instance-segmentation-preprocessor`，`train`字段表示模型训练时所对应的预处理，`val`字段表示模型推理时所对应的预处理：\n",
        "```json\n",
        "\"preprocessor\": {\n",
        "    \"type\": \"image-instance-segmentation-preprocessor\",\n",
        "    \"train\": [\n",
        "        {\n",
        "        \"type\": \"LoadImageFromFile\"\n",
        "        },\n",
        "        {\n",
        "            \"type\": \"LoadAnnotations\",\n",
        "            \"with_bbox\": true,\n",
        "            \"with_mask\": true\n",
        "        },\n",
        "        {\n",
        "            \"type\": \"Resize\",\n",
        "            \"img_scale\": [\n",
        "                [666, 320],\n",
        "                [666, 400]\n",
        "            ],\n",
        "            \"multiscale_mode\": \"range\",\n",
        "            \"keep_ratio\": true\n",
        "        },\n",
        "        {\n",
        "            \"type\": \"RandomFlip\",\n",
        "            \"flip_ratio\": 0.5\n",
        "        },\n",
        "        {\n",
        "            \"type\": \"Normalize\",\n",
        "            \"mean\": [123.675, 116.28, 103.53],\n",
        "            \"std\": [58.395, 57.12, 57.375],\n",
        "            \"to_rgb\": true\n",
        "        },\n",
        "        {\n",
        "            \"type\": \"Pad\",\n",
        "            \"size_divisor\": 32\n",
        "        },\n",
        "        {\n",
        "            \"type\": \"DefaultFormatBundle\"\n",
        "        },\n",
        "        {\n",
        "            \"type\": \"Collect\",\n",
        "            \"keys\": [\"img\", \"gt_bboxes\", \"gt_labels\", \"gt_masks\"],\n",
        "            \"meta_keys\": [\n",
        "                \"filename\", \"ori_filename\", \"ori_shape\",\n",
        "                \"img_shape\", \"pad_shape\", \"scale_factor\", \"flip\",\n",
        "                \"flip_direction\", \"img_norm_cfg\", \"ann_file\",\n",
        "                \"classes\"\n",
        "            ]\n",
        "        }\n",
        "    ],\n",
        "    \"val\": [\n",
        "        {\n",
        "        \"type\": \"LoadImageFromFile\"\n",
        "        },\n",
        "        {\n",
        "            \"type\": \"Resize\",\n",
        "            \"img_scale\": [1333, 800],\n",
        "            \"keep_ratio\": true\n",
        "        },\n",
        "        {\n",
        "            \"type\": \"RandomFlip\",\n",
        "            \"flip_ratio\": 0.0\n",
        "        },\n",
        "        {\n",
        "            \"type\": \"Normalize\",\n",
        "            \"mean\": [123.675, 116.28, 103.53],\n",
        "            \"std\": [58.395, 57.12, 57.375],\n",
        "            \"to_rgb\": true\n",
        "        },\n",
        "        {\n",
        "            \"type\": \"Pad\",\n",
        "            \"size_divisor\": 32\n",
        "        },\n",
        "        {\n",
        "            \"type\": \"ImageToTensor\",\n",
        "            \"keys\": [\"img\"]\n",
        "        },\n",
        "        {\n",
        "            \"type\": \"Collect\",\n",
        "            \"keys\": [\"img\"],\n",
        "            \"meta_keys\": [\n",
        "                \"filename\", \"ori_filename\", \"ori_shape\",\n",
        "                \"img_shape\", \"pad_shape\", \"scale_factor\", \"flip\",\n",
        "                \"flip_direction\", \"img_norm_cfg\", \"ann_file\",\n",
        "                \"classes\"\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        "},\n",
        "```\n",
        "当前`image-instance-segmentation-preprocessor`提供了常用的图像分割预处理方法，包括`Resize`，`RandomFlip`，`Normalize`，`Pad`等，此处各处理函数借鉴了.ipynbetetcion，具体使用方式可参考.ipynbetection的[使用文档](https://.ipynbetection.readthedocs.io/en/stable/api.html#module-.ipynbet.datasets.pipelines)。\n",
        "注意，此处`meta_keys`需包涵\"ann_file\"，\"classes\"，方便后续Metric做评估。\n",
        "用户也可根据需要定制自己的Preprocessor，具体使用方法可参考 Preprocessor接口文档： ？？？ \n",
        "### 训练\n",
        "由trainer相关的接口文档可以了解到，训练过程核心流程由dataset、dataloader、optimizer、lr_scheduler和hooks等组件功能组成，具体是通过在configuration.json配置文件中申明的方式注册进入trainer的流程中，具体参考： ？？？ \n",
        "#### 基础配置\n",
        "在训练开始前需要配置好相应的trainer配置文件， 下面给一个完整的实例分割下游任务finetune的配置。\n",
        "用户在实际使用过程中，如果示例无法提供帮助，可以根据自己实际训练要求，针对optimizer/lr_scheduler/hooks进行定制注册，并在配置文件中通过type字段申明相应定制方法进行使用。\n",
        "```json\n",
        "\"train\": {\n",
        "    \"dataloader\": {\n",
        "        \"batch_size_per_gpu\": 1,\n",
        "        \"workers_per_gpu\": 0\n",
        "    },\n",
        "    \"optimizer\": {\n",
        "        \"type\": \"AdamW\",\n",
        "        \"lr\": 0.00001,\n",
        "        \"weight_decay\": 0.05\n",
        "    },\n",
        "    \"lr_scheduler\": {\n",
        "        \"type\": \"MultiStepLR\",\n",
        "        \"milestones\": [],\n",
        "        \"gamma\": 0.1\n",
        "    },\n",
        "    \"max_epochs\": 1,\n",
        "    \"hooks\": [\n",
        "        {\n",
        "            \"type\": \"CheckpointHook\",\n",
        "            \"interval\": 1\n",
        "        },\n",
        "        {\n",
        "            \"type\": \"TextLoggerHook\",\n",
        "            \"interval\": 1\n",
        "        },\n",
        "        {\n",
        "            \"type\": \"IterTimerHook\"\n",
        "        },\n",
        "        {\n",
        "            \"type\": \"EvaluationHook\",\n",
        "            \"interval\": 1\n",
        "        }\n",
        "    ]\n",
        "},\n",
        "\n",
        "\"evaluation\": {\n",
        "    \"dataloader\": {\n",
        "        \"batch_size_per_gpu\": 1,\n",
        "        \"workers_per_gpu\": 0\n",
        "    },\n",
        "    \"metrics\": [\"image-ins-seg-coco-metric\"]\n",
        "},\n",
        "```\n",
        "其中，`train`字段定义了训练流程相关的参数配置，`evaluation`字段定义了模型评估时所用的配置。\n",
        "同时，设置模型pretrain状态为true：\n",
        "```json\n",
        "{\n",
        "    ...\n",
        "    \"model\": {\n",
        "        ...\n",
        "        \"pretrained\": true,\n",
        "        ...\n",
        "    },\n",
        "    ...\n",
        "    \n",
        "}\n",
        "```\n",
        "有了上述配置，可通过如下代码进行模型的finetune训练：\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "from functools import partial\n",
        "\n",
        "from modelscope.hub.snapshot_download import snapshot_download\n",
        "from modelscope.models.cv.image_instance_segmentation import \\\n",
        "    ImageInstanceSegmentationCocoDataset, CascadeMaskRCNNSwinModel\n",
        "from modelscope.trainers import build_trainer\n",
        "from modelscope.utils.config import Config\n",
        "from modelscope.utils.constant import ModelFile\n",
        "\n",
        "from mmcv.parallel import collate\n",
        "\n",
        "\n",
        "model_id = 'damo/cv_swin-b_image-instance-segmentation_coco'\n",
        "cache_path = snapshot_download(model_id)\n",
        "\n",
        "dataset_path = os.path.join(cache_path, 'Pets.zip')\n",
        "with zipfile.ZipFile(dataset_path, 'r') as zipf:\n",
        "    zipf.extractall(cache_path)\n",
        "\n",
        "data_root = cache_path + '/Pets/'\n",
        "classes = ('Cat', 'Dog')\n",
        "\n",
        "train_dataset = ImageInstanceSegmentationCocoDataset(\n",
        "    ann_file=data_root + 'annotations/instances_train.json',\n",
        "    img_prefix=data_root + 'images/train/',\n",
        "    classes=classes,\n",
        "    test_mode=False)\n",
        "\n",
        "eval_dataset = ImageInstanceSegmentationCocoDataset(\n",
        "    ann_file=data_root + 'annotations/instances_val.json',\n",
        "    img_prefix=data_root + 'images/val/',\n",
        "    classes=classes,\n",
        "    test_mode=True)\n",
        "\n",
        "tmp_dir = \"/tmp\"\n",
        "config_path = os.path.join(cache_path, ModelFile.CONFIGURATION)\n",
        "cfg = Config.from_file(config_path)\n",
        "samples_per_gpu = cfg.train.dataloader.batch_size_per_gpu\n",
        "\n",
        "# 注：当自定义数据集类别数少于预训练模型预定义的类别数时，可以选择不修改模型结构，\n",
        "# 而在后处理滤去无效类别id；建议实际使用时根据需要修改模型结构配置中的num_classes值\n",
        "model = CascadeMaskRCNNSwinModel.from_pretrained(cache_path)\n",
        "kwargs = dict(\n",
        "    cfg_file=os.path.join(cache_path, ModelFile.CONFIGURATION),\n",
        "    model=model,\n",
        "    data_collator=partial(collate, samples_per_gpu=samples_per_gpu),\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    work_dir=tmp_dir)\n",
        "\n",
        "trainer = build_trainer(\n",
        "    name='image-instance-segmentation', default_args=kwargs)\n",
        "trainer.train()\n",
        "\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "这里使用名字为'image-instance-segmentation'的定制trainer，collate_fn借助mmcv的实现。\n",
        "#### 高级配置\n",
        "在实际过程用户可能会频繁对配置进行调整，不光是训练相关的参数，很可能对应的下游任务都会变化，因此我们提供了高级配置方式供算法用户使用，从而减少不必要的configuration文件改写。\n",
        "自定义cfg file， 通过覆盖更新cfg_file文件进行代码内的配置调整：\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "from functools import partial\n",
        "\n",
        "from modelscope.hub.snapshot_download import snapshot_download\n",
        "from modelscope.models.cv.image_instance_segmentation import \\\n",
        "    ImageInstanceSegmentationCocoDataset, CascadeMaskRCNNSwinModel\n",
        "from modelscope.trainers import build_trainer\n",
        "from modelscope.utils.config import Config\n",
        "from modelscope.utils.constant import ModelFile\n",
        "\n",
        "from mmcv.parallel import collate\n",
        "\n",
        "\n",
        "model_id = 'damo/cv_swin-b_image-instance-segmentation_coco'\n",
        "cache_path = snapshot_download(model_id)\n",
        "\n",
        "dataset_path = os.path.join(cache_path, 'Pets.zip')\n",
        "with zipfile.ZipFile(dataset_path, 'r') as zipf:\n",
        "    zipf.extractall(cache_path)\n",
        "\n",
        "data_root = cache_path + '/Pets/'\n",
        "classes = ('Cat', 'Dog')\n",
        "\n",
        "train_dataset = ImageInstanceSegmentationCocoDataset(\n",
        "    ann_file=data_root + 'annotations/instances_train.json',\n",
        "    img_prefix=data_root + 'images/train/',\n",
        "    classes=classes,\n",
        "    test_mode=False)\n",
        "\n",
        "eval_dataset = ImageInstanceSegmentationCocoDataset(\n",
        "    ann_file=data_root + 'annotations/instances_val.json',\n",
        "    img_prefix=data_root + 'images/val/',\n",
        "    classes=classes,\n",
        "    test_mode=True)\n",
        "\n",
        "tmp_dir = \"/tmp\"\n",
        "config_path = os.path.join(cache_path, ModelFile.CONFIGURATION)\n",
        "cfg = Config.from_file(config_path)\n",
        "cfg.train.max_epochs = 2\n",
        "cfg.train.work_dir = tmp_dir\n",
        "# 修改log间隔\n",
        "for i in range(len(cfg.train.hooks)):\n",
        "    if cfg.train.hooks[i].type == \"TextLoggerHook\":\n",
        "        cfg.train.hooks[i].interval = 10\n",
        "        break\n",
        "# 修改模型输出类别维度，最后一层随机初始化\n",
        "for i in range(len(cfg.model.roi_head.bbox_head)):\n",
        "    cfg.model.roi_head.bbox_head[i].num_classes = len(classes)\n",
        "cfg.model.roi_head.mask_head.num_classes = len(classes)\n",
        "cfg_file = os.path.join(tmp_dir, 'config.json')\n",
        "cfg.dump(cfg_file)\n",
        "\n",
        "samples_per_gpu = cfg.train.dataloader.batch_size_per_gpu\n",
        "\n",
        "model = CascadeMaskRCNNSwinModel.from_pretrained(cache_path, cfg_dict=cfg)\n",
        "kwargs = dict(\n",
        "    cfg_file=cfg_file,\n",
        "    model=model,\n",
        "    data_collator=partial(collate, samples_per_gpu=samples_per_gpu),\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    work_dir=tmp_dir)\n",
        "\n",
        "trainer = build_trainer(\n",
        "    name='image-instance-segmentation', default_args=kwargs)\n",
        "trainer.train()\n",
        "\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 评估\n",
        "#### 交叉验证\n",
        "交叉验证是在train时同步进行的，基于在配置文件中的 train.hooks的 EvaluationHook，具体配置如下：\n",
        "```json\n",
        "{\n",
        "    ...\n",
        "    \"train\": \n",
        "    {\n",
        "        ...\n",
        "        \"hooks\": \n",
        "        [\n",
        "            ..., \n",
        "            {\n",
        "            \"type\": \"EvaluationHook\",\n",
        "            \"by_epoch\": true,\n",
        "            \"interval\": 1\n",
        "            }，\n",
        "        ]\n",
        "    },\n",
        "}\n",
        "```\n",
        "\n",
        "用户可以根据自己实际情况进行调整，也可自行注册相应hook，并通过type字段注册在配置文件中进行调用。\n",
        "#### 训练后验证\n",
        "\n",
        "1. 指定并加载验证数据集\n",
        "2. build_trainer\n",
        "3. 调用evaluate方法\n",
        "\n",
        "如下代码展示了模型的验证流程\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true
      },
      "source": [
        "mport os\n",
        "from functools import partial\n",
        "\n",
        "from modelscope.hub.snapshot_download import snapshot_download\n",
        "from modelscope.models.cv.image_instance_segmentation import \\\n",
        "    CascadeMaskRCNNSwinModel\n",
        "from modelscope.trainers import build_trainer\n",
        "from modelscope.utils.config import Config, ConfigDict\n",
        "from modelscope.utils.constant import ModelFile\n",
        "\n",
        "from mmcv.parallel import collate\n",
        "\n",
        "model_id = 'damo/cv_swin-b_image-instance-segmentation_coco'\n",
        "cache_path = snapshot_download(model_id)\n",
        "config_path = os.path.join(cache_path, ModelFile.CONFIGURATION)\n",
        "cfg = Config.from_file(config_path)\n",
        "\n",
        "max_epochs = cfg.train.max_epochs\n",
        "samples_per_gpu = cfg.train.dataloader.batch_size_per_gpu\n",
        "train_data_cfg = ConfigDict(\n",
        "                name='pets_small', split='train', test_mode=False)\n",
        "val_data_cfg = ConfigDict(\n",
        "                name='pets_small', split='validation', test_mode=True)\n",
        "\n",
        "train_dataset = MsDataset.load(\n",
        "    dataset_name=train_data_cfg.name,\n",
        "    split=train_data_cfg.split,\n",
        "    test_mode=train_data_cfg.test_mode)\n",
        "\n",
        "eval_dataset = MsDataset.load(\n",
        "    dataset_name=val_data_cfg.name,\n",
        "    split=val_data_cfg.split,\n",
        "    test_mode=val_data_cfg.test_mode)\n",
        "\n",
        "tmp_dir = \"/tmp\"\n",
        "samples_per_gpu = cfg.train.dataloader.batch_size_per_gpu\n",
        "\n",
        "# 注：当自定义数据集类别数少于预训练模型预定义的类别数时，可以选择不修改模型结构，\n",
        "# 而在后处理滤去无效类别id；建议实际使用时根据需要修改模型结构配置中的num_classes值\n",
        "model = CascadeMaskRCNNSwinModel.from_pretrained(cache_path)\n",
        "kwargs = dict(\n",
        "    cfg_file=os.path.join(cache_path, ModelFile.CONFIGURATION),\n",
        "    model=model,\n",
        "    data_collator=partial(collate, samples_per_gpu=samples_per_gpu),\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    work_dir=tmp_dir)\n",
        "\n",
        "trainer = build_trainer(\n",
        "    name='image-instance-segmentation', default_args=kwargs)\n",
        "trainer.train()\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 指标\n",
        "指标用来衡量某个具体任务的验证结果，用户可以查看如下package找到已支持指标类的列表：\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true
      },
      "source": [
        "import modelscope.metrics\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "对于实例分割，modelscope提供了一个较为通用的指标：\n",
        "\n",
        "- ImageInstanceSegmentationCOCOMetric\n",
        "   - 指标名称为image-ins-seg-coco-metric\n",
        "   - 为COCO标准mAP指标，返回mask mAP和box mAP等\n",
        "\n",
        "代码中我们为支持finetune的各任务类型指定了默认metric类：\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true
      },
      "source": [
        "from modelscope.metrics.builder import task_default_metrics\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "image-segmentation任务默认调用`image_ins_seg_coco_metric`指标。用户也可以根据需要在modelscope中注册使用自定义的指标类型。\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
